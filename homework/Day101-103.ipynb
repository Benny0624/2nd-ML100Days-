{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nfor dirname, _, filenames in os.walk('/kaggle/input'):\\n    for filename in filenames:\\n        print(os.path.join(dirname, filename))\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import those packages that I need\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm # to see the running process\n",
    "from skimage.io import imread, imshow # to read the image from workspace\n",
    "from skimage.transform import resize # resize those data to a certain size for training\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "%matplotlib inline\n",
    "import os\n",
    "import keras \n",
    "from keras.utils.np_utils import to_categorical # for One-Hot Encoding\n",
    "from sklearn.model_selection import train_test_split # for generating validation set (X_val, Y_val)\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50 # the well-known CNN model imported for transfer learning\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau # built-in callbacks in keras \n",
    "from keras.preprocessing.image import ImageDataGenerator # for data augmentation\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam # the model optimizer that I choose for this task\n",
    "from keras.regularizers import l1,l2 # L1, L2 regularization to avoid overfitting\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import itertools\n",
    "\n",
    "# the following remark(code) can be used to see all the files in the 'input' folder in the Workspace\n",
    "\n",
    "'''\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for loading training images and labeling them in the same time according to which folder they come from,\n",
    "# 'dogs' or 'cats'\n",
    "\n",
    "def read_image_train(folder,resize_hight = 224, resize_width = 224):\n",
    "    \n",
    "    DATA_ROOT = \"C:/Users/user/Desktop/MLcontest/ML100/Part08/kaggle_dogcat/\"\n",
    "    dogs = np.ones((1,resize_hight,resize_width,3))\n",
    "    cats = np.ones((1,resize_hight,resize_width,3))\n",
    "    \n",
    "    dogs_label=[]\n",
    "    cats_label=[]\n",
    "    \n",
    "    for image_type in os.listdir(os.path.join(DATA_ROOT,folder)):\n",
    "        # print(image_type)\n",
    "        if image_type == 'dogs':\n",
    "            for image_name in tqdm(os.listdir(os.path.join(DATA_ROOT,folder + '/' + image_type))):\n",
    "                # print(image_name)\n",
    "                im = imread(os.path.join(DATA_ROOT,folder + '/' + image_type + '/' + image_name))\n",
    "                # print(im.shape)\n",
    "                dog_size = im.size\n",
    "                # if dog_size >= (resize_hight*resize_width):\n",
    "                if dog_size >= 0:\n",
    "                    im_resized = resize(im, (resize_hight, resize_width), anti_aliasing=True)\n",
    "                    im_resized = im_resized[np.newaxis,:,:,:]\n",
    "                    # print(im_resized.shape)\n",
    "                    dogs = np.concatenate((dogs,im_resized),axis=0)\n",
    "                    dogs_label.append(0)\n",
    "                    \n",
    "        elif image_type == 'cats':\n",
    "            for image_name in tqdm(os.listdir(os.path.join(DATA_ROOT,folder + '/' + image_type))):\n",
    "                # print(image_name)\n",
    "                im = imread(os.path.join(DATA_ROOT,folder + '/' + image_type + '/' + image_name))\n",
    "                # print(im.shape)\n",
    "                cat_size = im.size\n",
    "                # if cat_size >= (resize_hight*resize_width):\n",
    "                if cat_size >= 0:\n",
    "                    im_resized = resize(im, (resize_hight, resize_width), anti_aliasing=True)\n",
    "                    im_resized = im_resized[np.newaxis,:,:,:]\n",
    "                    # print(im_resized.shape)\n",
    "                    cats = np.concatenate((cats,im_resized),axis=0)\n",
    "                    cats_label.append(1)\n",
    "                    \n",
    "    dogs = np.delete(dogs,(0),axis=0)\n",
    "    cats = np.delete(cats,(0),axis=0)\n",
    "    image_array = np.concatenate((dogs,cats),axis = 0)\n",
    "    print(\"The shape of image\", image_array.shape)\n",
    "\n",
    "    dogs_label = np.asarray(dogs_label)\n",
    "    cats_label = np.asarray(cats_label)\n",
    "    label = np.concatenate((dogs_label,cats_label),axis=0)\n",
    "    print(\"The shape of image label :\", label.shape)\n",
    "    \n",
    "    return image_array, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for loading the testing data and getting their ID at the same time\n",
    "# the reason that getting the ID is for the submission csv file because the probability of class should match the image name\n",
    "\n",
    "def read_image_test(folder,resize_hight = 224, resize_width = 224):\n",
    "    \n",
    "    DATA_ROOT = \"C:/Users/user/Desktop/MLcontest/ML100/Part08/kaggle_dogcat/\"\n",
    "    img = np.ones((1,resize_hight,resize_width,3))\n",
    "    names = []\n",
    "    \n",
    "    for image_name in tqdm(os.listdir(os.path.join(DATA_ROOT,folder))):\n",
    "        # print(image_name)\n",
    "        im = imread(os.path.join(DATA_ROOT,folder + '/' + image_name))\n",
    "        # print(im.shape)\n",
    "        \n",
    "        im_resized = resize(im, (resize_hight, resize_width), anti_aliasing=True)\n",
    "        im_resized = im_resized[np.newaxis,:,:,:]\n",
    "        # print(im_resized.shape)\n",
    "        img = np.concatenate((img,im_resized),axis=0)\n",
    "        name_split = image_name.split('.')\n",
    "        names.append(name_split[0])\n",
    "\n",
    "                    \n",
    "    img = np.delete(img,(0),axis=0)\n",
    "    names = np.asarray(names)\n",
    "    print(\"The shape of image\",img.shape)\n",
    "    print(\"The shape of image name :\", names.shape)\n",
    "    \n",
    "    return img , names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2000/2000 [3:25:26<00:00,  6.16s/it]\n",
      " 99%|███████████████████████████████████████████████████████████████████████████▏| 1977/2000 [5:27:03<27:51, 72.69s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-10683ddbbaa9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# loading images and transform them into numpy array with labels (cats: 1,dogs:0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_image_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_image_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-96b47d4bf938>\u001b[0m in \u001b[0;36mread_image_train\u001b[1;34m(folder, resize_hight, resize_width)\u001b[0m\n\u001b[0;32m     24\u001b[0m                     \u001b[0mim_resized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mim_resized\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                     \u001b[1;31m# print(im_resized.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                     \u001b[0mdogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdogs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mim_resized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m                     \u001b[0mdogs_label\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Now, We are able to load those data that we need for this task.\n",
    "# loading images and transform them into numpy array with labels (cats: 1,dogs:0)\n",
    "\n",
    "x_train, y_train = read_image_train('train')\n",
    "x_test, names = read_image_test('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization\n",
    "x_train = x_train.astype('float32')\n",
    "# x_train /= 255\n",
    "x_train_mean = np.mean(x_train)\n",
    "x_train_std = np.std(x_train)\n",
    "x_train -= x_train_mean\n",
    "x_train /= x_train_std\n",
    "\n",
    "x_test = x_test.astype('float32')\n",
    "# x_test /= 255\n",
    "x_test_mean = np.mean(x_test)\n",
    "x_test_std = np.std(x_test)\n",
    "x_test -= x_test_mean\n",
    "x_test /= x_test_std\n",
    "\n",
    "# label : one-hot encoding \n",
    "num_class = 2\n",
    "y_trainHOT = keras.utils.to_categorical(y_train, num_class)\n",
    "\n",
    "# extract 1/4 training data as validation data\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(x_train, y_trainHOT, test_size=0.25, random_state=42)\n",
    "\n",
    "# print out the shape of images and labels\n",
    "print(\"The shape of x_train: \",X_train.shape)\n",
    "print(\"The shape of y_train: \",Y_train.shape)\n",
    "print(\"The shape of x_val: \",X_val.shape)\n",
    "print(\"The shape of y_val: \",Y_val.shape)\n",
    "\n",
    "print(\"The shape of x_test: \",x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "resize_hight = 224\n",
    "resize_width = 224\n",
    "NUM_CLASSES = 2\n",
    "batch_size = 4  \n",
    "epochs = 50\n",
    "learning_rate = 1e-5\n",
    "aug = False\n",
    "initial_train = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning: ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the ResNet50 from keras.applications.resnet50 (the packages that i import above!)\n",
    "ResNet50_model = ResNet50(include_top=False, weights='imagenet', input_tensor=None, input_shape=(resize_hight,resize_width,3))\n",
    "\n",
    "x = ResNet50_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output_layer = Dense(NUM_CLASSES, activation='softmax', name='softmax')(x)\n",
    "ResNet50_model_final = Model(inputs=ResNet50_model.input, outputs=output_layer)\n",
    "\n",
    "ResNet50_model_final.compile(optimizer=Adam(lr=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "ResNet50_model_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation: Although I may not use it, it is worth trying :)\n",
    "train_datagen = ImageDataGenerator(shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator(shear_range=0.2,\n",
    "                                 zoom_range=0.2,\n",
    "                                 horizontal_flip=True)\n",
    "\n",
    "# callbacks\n",
    "reduce_lr = ReduceLROnPlateau(factor=0.5, \n",
    "                              min_lr=1e-12, \n",
    "                              monitor='val_loss', \n",
    "                              patience=9, \n",
    "                              verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor=\"val_acc\", \n",
    "                          patience=5, \n",
    "                          verbose=1)\n",
    "\n",
    "# save the model for future usage\n",
    "model_save='model_shuffle_noAug_allimage_bs4.h5' \n",
    "model_checkpoint = ModelCheckpoint(filepath=model_save, \n",
    "                                   monitor=\"val_loss\", \n",
    "                                   save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the accuracy and loss during every epoch\n",
    "\n",
    "plt.plot(range(len(train_loss)), train_loss, label=\"train loss\")\n",
    "plt.plot(range(len(valid_loss)), valid_loss, label=\"valid loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(len(train_acc)), train_acc, label=\"train accuracy\")\n",
    "plt.plot(range(len(valid_acc)), valid_acc, label=\"valid accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functin that plot the confusion matrix, helping understand the performance of the model\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=True,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize = (5,5))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        cm=(cm*100+.01).astype(int)/100\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to plot the ROC curve to see the performance of our model\n",
    "\n",
    "Y_val_roc = np.argmax(Y_val,axis=1) # ground truth\n",
    "# ResNet50_model_final = keras.models.load_model(\"/kaggle/input/cats-dogsclassification/model_noshuffle_noAug_allimage.h5\")\n",
    "y_probas = ResNet50_model_final.predict(X_val) # prediction (probability)\n",
    "Y_pred_classes = np.argmax(y_probas,axis=1) \n",
    "fpr, tpr, _ = roc_curve(Y_val_roc,Y_pred_classes)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "fig = plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the confusion matrix\n",
    "dict_characters = {0:'Dog',1:'Cat'}\n",
    "confusion_mtx = confusion_matrix(Y_val_roc, Y_pred_classes) \n",
    "plot_confusion_matrix(confusion_mtx, classes =list(dict_characters.values()))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
